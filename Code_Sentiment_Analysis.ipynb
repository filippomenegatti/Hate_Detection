{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code - Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CKCGmxHKfA9T",
        "fY0UH4zne6fc",
        "UX_krm8Yfskl",
        "R9rKuwLtc_u2",
        "AGd0kVlltms2",
        "jITagIcRW1Os"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filippomenegatti/Hate_Detection/blob/main/Code_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2HUtBevfEdQ"
      },
      "source": [
        "# Hate Speech Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKCGmxHKfA9T"
      },
      "source": [
        "## Librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QriPPTYeisMf"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import requests\n",
        "import string\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import *\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import linear_model, datasets, metrics\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY0UH4zne6fc"
      },
      "source": [
        "## Set Up e Funzioni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dN9ik6CgKqh"
      },
      "source": [
        "nltk_stopwords = stopwords.words('english')\n",
        "nltk_stopwords.extend(['rt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz-qUusDAXTa"
      },
      "source": [
        "def preprocessing(text, tokenize = False, stopwords = [], alphabetic=True, stem=False, lem=False, proc_type=None):\n",
        "\n",
        "  '''\n",
        "  This function to perform some preprocessing on the data:\n",
        "    - The standard list of stopwords is empty and can be arbitrarily replaced.\n",
        "    - It is possible to choose to remove or keep the non-alphabetical tokens.\n",
        "    - it is possible to choose which kind of elaboration perform between nothing, lemmatization, and stemming.\n",
        "    - ...\n",
        "  '''\n",
        "  \n",
        "  #create tokens from text\n",
        "  tokens = word_tokenize(text.lower())\n",
        "\n",
        "  if alphabetic == True: # remove all tokens that are not alphabetic\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "  else:\n",
        "    tokens = tokens\n",
        " \n",
        "  # remove all stopwords\n",
        "  tokens = [word for word in tokens if not word in stopwords]\n",
        "\n",
        "  # perform stemming or lemmatization and choose what type\n",
        "  if stem == True:\n",
        "    method = proc_type\n",
        "    stem_tokens = [method.stem(token) for token in tokens]\n",
        "    if tokenize == False:\n",
        "      stem_tokens = ' '.join(stem_tokens)\n",
        "      return stem_tokens\n",
        "    else:\n",
        "      return stem_tokens\n",
        "  \n",
        "  elif lem == True:\n",
        "    method = proc_type\n",
        "    lem_tokens = [method.lemmatize(token) for token in tokens]\n",
        "    if tokenize == False:\n",
        "      lem_tokens = ' '.join(lem_tokens)\n",
        "      return lem_tokens\n",
        "    else:\n",
        "      return lem_tokens\n",
        "  \n",
        "  else:\n",
        "    if tokenize == False:\n",
        "      tokens = ' '.join(tokens)\n",
        "      return tokens\n",
        "    else:\n",
        "      return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96LYlkIuExw3"
      },
      "source": [
        "def tfidf_vec(input, ngrams):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "      ngram_range=ngrams,\n",
        "      use_idf=True,\n",
        "      lowercase = False,\n",
        "      smooth_idf=False,\n",
        "      decode_error='replace',\n",
        "      max_features=10000,\n",
        "      min_df=5,\n",
        "      max_df=0.501\n",
        "      )\n",
        "  matrix = vectorizer.fit_transform(input).toarray()\n",
        "  return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX_krm8Yfskl"
      },
      "source": [
        "## Caricamento del data set classificato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s920gStMw6ch"
      },
      "source": [
        "Download of labeled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oia2jtzojiNh"
      },
      "source": [
        "labeled_data = pd.read_csv('https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv')\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "labeled_data = labeled_data.drop(columns=['Unnamed: 0'])\n",
        "display(labeled_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlWRwFZWAj04"
      },
      "source": [
        "labeled_data['clean_sents'] = labeled_data.apply(lambda row: preprocessing(row['tweet'], stopwords = ['rt'],\n",
        "                                                                           stem = True, lem = False, proc_type = PorterStemmer(), tokenize = False), axis=1)\n",
        "labeled_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc_jiC6pbgeA"
      },
      "source": [
        "labeled_data.drop(['count', 'hate_speech', 'offensive_language', 'neither', 'tweet'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB3v9gp0SCfG"
      },
      "source": [
        "#use only if tokenize was set equal to false (default) in preprocessing function\n",
        "labeled_data['tokens'] = labeled_data['clean_sents'].map(lambda x: word_tokenize(x))\n",
        "\n",
        "labeled_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv4Lkj_gRD4x"
      },
      "source": [
        "#Get POS tags for tweets and save as a string\n",
        "tweet_tags = []\n",
        "for t in labeled_data['tokens']:\n",
        "  tags = nltk.pos_tag(t)\n",
        "  tag_list = [x[1] for x in tags]\n",
        "  tag_str = \" \".join(tag_list)\n",
        "  tweet_tags.append(tag_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0wr7k3NUT4y"
      },
      "source": [
        "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
        "pos_vectorizer = TfidfVectorizer(\n",
        "    tokenizer=None,\n",
        "    lowercase=False,\n",
        "    preprocessor=None,\n",
        "    ngram_range=(1, 3),\n",
        "    stop_words=None,\n",
        "    use_idf=False,\n",
        "    smooth_idf=False,\n",
        "    norm=None,\n",
        "    decode_error='replace',\n",
        "    max_features=5000,\n",
        "    min_df=5,\n",
        "    max_df=0.501,\n",
        "    )\n",
        "\n",
        "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVVryInI_guc"
      },
      "source": [
        "X = tfidf_vec(labeled_data.clean_sents, (1,3))\n",
        "y = labeled_data['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eFYlZnEVqXM"
      },
      "source": [
        "X_pos = np.concatenate([X, pos], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbKi2vEBVnjn"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_pos, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9rKuwLtc_u2"
      },
      "source": [
        "## SMOTE Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bjTm-PHbytd"
      },
      "source": [
        "pd.value_counts(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXukPp8MaVag"
      },
      "source": [
        "plt.bar(np.arange(0, 3), np.bincount(y))\n",
        "plt.title('Frequency of the classes')\n",
        "plt.xlabel('classes')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua7fTRdZc_hK"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flfc37npc_eP"
      },
      "source": [
        "# transform the dataset\n",
        "strategy = {1:8638}\n",
        "undersample = RandomUnderSampler(sampling_strategy=strategy)\n",
        "X_train_smote, y_train_smote = undersample.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii1QZ_fgjTnp"
      },
      "source": [
        "X_train_smote.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJrQrBd2c_bR"
      },
      "source": [
        "pd.value_counts(y_train_smote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGd0kVlltms2"
      },
      "source": [
        "## save/load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz_vH1f8tkTq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/Sentiment_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yd8FWfRiYAS"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNSuTYg6h5k0"
      },
      "source": [
        "# with open('portstem_data.pickle', 'wb') as output:\n",
        "#     pickle.dump(X_train_smote, output)\n",
        "# with open('portstem_target.pickle', 'wb') as output:\n",
        "#     pickle.dump(y_train_smote, output)\n",
        "# with open('portstem_test.pickle', 'wb') as output:\n",
        "#     pickle.dump(X_test, output)\n",
        "# with open('portstem_test_target.pickle', 'wb') as output:\n",
        "#     pickle.dump(y_test, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNEacqvh5iA"
      },
      "source": [
        "#load data\n",
        "\n",
        "with open('portstem_target.pickle', 'rb') as data:\n",
        "    y_train = pickle.load(data)\n",
        "with open('portstem_data.pickle', 'rb') as data:\n",
        "    X_train = pickle.load(data)\n",
        "\n",
        "with open('portstem_test_target.pickle', 'rb') as data:\n",
        "    y_test = pickle.load(data)\n",
        "with open('portstem_test.pickle', 'rb') as data:\n",
        "    X_test = pickle.load(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jITagIcRW1Os"
      },
      "source": [
        "## Modelli base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztqf54opBsdk"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GQJ6hvbR-qp"
      },
      "source": [
        "classifier = RandomForestClassifier(n_estimators=300, random_state=42, verbose = 40, class_weight='balanced')\n",
        "classifier.fit(X_train, y_train) \n",
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT_AKGl1R-oa"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('The Accuracy Score is:',accuracy_score(y_test, y_pred))\n",
        "print('The Weighted F1 Score is:',f1_score(y_test, y_pred, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxyFwBNFduzY"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import linear_model, datasets, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXoBaZa1cMZa"
      },
      "source": [
        "conf_matrix=tf.math.confusion_matrix(y_test,y_pred,num_classes=3).numpy()\n",
        "con_mat_norm = np.around(conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "print(con_mat_norm)\n",
        "plt.matshow(con_mat_norm,cmap=plt.cm.hot)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWv59gUvXJyt"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_test,y_scores, classNames):\n",
        "    # y_test=np.argmax(y_test, axis=1)\n",
        "    # y_scores=np.argmax(y_scores, axis=1)\n",
        "    classes = len(classNames)\n",
        "    cm = confusion_matrix(y_test, y_scores)\n",
        "    print(\"**** Confusion Matrix ****\")\n",
        "    print(cm)\n",
        "    print(\"**** Classification Report ****\")\n",
        "    print(classification_report(y_test, y_scores, target_names=classNames))\n",
        "    con = np.zeros((classes,classes))\n",
        "    for x in range(classes):\n",
        "        for y in range(classes):\n",
        "            con[x,y] = cm[x,y]/np.sum(cm[x,:])\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    sns.set(font_scale=1.0) # for label size\n",
        "    df = sns.heatmap(con, annot=True,fmt='.2', xticklabels= classNames , yticklabels= classNames)\n",
        "    df.figure.savefig(\"image2.png\")\n",
        "\n",
        "classNames = ['0', '1', '2'] \n",
        "plot_confusion_matrix(y_test,y_pred, classNames) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NsoNAXrBu_R"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKptC2f6R-mF"
      },
      "source": [
        "### Naive Bayes\n",
        "alpha = np.linspace(1, 100, 100)\n",
        "nb_grid = GridSearchCV(estimator= MultinomialNB(),\n",
        "                       param_grid=dict(\n",
        "                           alpha = alpha),\n",
        "                  scoring=\"f1_weighted\",\n",
        "                  cv = 5)\n",
        "nb_grid.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "nb_grid_best_hyperparameter = nb_grid.best_estimator_.alpha\n",
        "\n",
        "nb_best_hyper = MultinomialNB(alpha = nb_grid_best_hyperparameter)\n",
        "nb_best_hyper.fit(X_train, y_train)\n",
        "\n",
        "np_y_preds = nb_best_hyper.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYUUHa0_R-jx"
      },
      "source": [
        "print('The best score is:',nb_grid.best_score_,'\\n')\n",
        "print('The best hyperparameter found is:',nb_grid_best_hyperparameter,'\\n')\n",
        "print('The classification report is: \\n',classification_report(y_test, np_y_preds))\n",
        "print('The Weighted F1 Score is:',f1_score(y_test, np_y_preds, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ijv5ALEBzjC"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b96ymQQyjPmN"
      },
      "source": [
        "svm = SVC()\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfNYhgs-2ClR"
      },
      "source": [
        "param_grid = { 'C':[0.1,1,100],\n",
        "              'kernel':['rbf','poly','sigmoid','linear'],\n",
        "              'degree':[1,2,3],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-0RRUA_2Cjf"
      },
      "source": [
        "grid = GridSearchCV(SVC(),\n",
        "                    param_grid,\n",
        "                    refit=True,\n",
        "                    cv = 5,\n",
        "                    verbose=40,\n",
        "                    n_jobs=-1)\n",
        "\n",
        "grid.fit(X_train_smote, y_train_smote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcraOW2v2Chi"
      },
      "source": [
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGwwWiuR2Cfs"
      },
      "source": [
        "grid_predictions = grid.predict(X_test)\n",
        "print(confusion_matrix(y_test,grid_predictions))\n",
        "print(classification_report(y_test,grid_predictions))  #Output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wq7iEVARWu"
      },
      "source": [
        "## Sparse Tensor Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urx0CZMk_bpy"
      },
      "source": [
        "!pip install stc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNw_JdcqR-cs"
      },
      "source": [
        "from stc import SparseTensorClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSI0Psv2R-Z-"
      },
      "source": [
        "models = {\n",
        "    'Multinomial NV': MultinomialNB(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost' : XGBClassifier()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54ruHU52E5j"
      },
      "source": [
        "train, test = train_test_split(labeled_data, test_size=0.25, random_state = 42)\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0efsPDW0gP2"
      },
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
        "X_train = vectorizer.fit_transform(train.clean_sents)\n",
        "X_test = vectorizer.transform(test.clean_sents)\n",
        "y_train, y_test = train['class'], test['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiiGvtEmTT5H"
      },
      "source": [
        "# transform the dataset\n",
        "strategy = {1:8638}\n",
        "undersample = RandomUnderSampler(sampling_strategy=strategy)\n",
        "X_train_smote, y_train_smote = undersample.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15TINQHay92g"
      },
      "source": [
        "for model_name, model in models.items():\n",
        "    print(\"Training: {}\".format(model_name))\n",
        "    models[model_name].fit(X_train_smote, y_train_smote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUwqy45PzldW"
      },
      "source": [
        "predictions = {}\n",
        "for model_name, model in models.items():\n",
        "    print(\"Predicting: {}\".format(model_name))\n",
        "    predictions[model_name] = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5smjHyUyC0K"
      },
      "source": [
        "json_train, json_test = [], []\n",
        "for i, doc in list(enumerate(train.clean_sents)):\n",
        "    json_train.append({'words': nltk.word_tokenize(doc), 'target': [train['class'][i]]})\n",
        "for i, doc in list(enumerate(test.clean_sents)):\n",
        "    json_test.append({'words': nltk.word_tokenize(doc)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvPly28MyH8X"
      },
      "source": [
        "STC = SparseTensorClassifier(features=['words'], targets=['target'])\n",
        "STC.fit(json_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ZGkVCs46id"
      },
      "source": [
        "expl_words = STC.explain()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDeMC3BZ6Cpe"
      },
      "source": [
        "#Top 10 per target\n",
        "expl_words['features'] = expl_words['features'].map(lambda x: x.replace(\"words: \", \"\"))\n",
        "hate = expl_words[expl_words.index == \"0\"]\n",
        "#hate['features'] = hate['features'].map(lambda x: x.replace(\"words: \", \"\"))\n",
        "hate.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a09ExWAE6hQJ"
      },
      "source": [
        "offensive = expl_words[expl_words.index == \"1\"]\n",
        "offensive.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRiZ0cyM9L_j"
      },
      "source": [
        "neutral = expl_words[expl_words.index == \"2\"]\n",
        "neutral.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNQ8NY_-DNsL"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wGAA_XiCPB9"
      },
      "source": [
        "#Word Cloud\n",
        "text_dict= dict(hate.values)\n",
        "\n",
        "# create the WordCloud object\n",
        "wordcloud = WordCloud(background_color='white', colormap= \"Dark2\")\n",
        "\n",
        "# generate the word cloud\n",
        "wordcloud.generate_from_frequencies(text_dict)\n",
        "\n",
        "#plot\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU96VH4zDfHh"
      },
      "source": [
        "text_dict= dict(offensive.values)\n",
        "\n",
        "# create the WordCloud object\n",
        "wordcloud = WordCloud(background_color='white', colormap= \"inferno\")\n",
        "\n",
        "# generate the word cloud\n",
        "wordcloud.generate_from_frequencies(text_dict)\n",
        "\n",
        "#plot\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqiHUaiVCPoM"
      },
      "source": [
        "text_dict= dict(neutral.values)\n",
        "\n",
        "# create the WordCloud object\n",
        "wordcloud = WordCloud(background_color='white')\n",
        "\n",
        "# generate the word cloud\n",
        "wordcloud.generate_from_frequencies(text_dict)\n",
        "\n",
        "#plot\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmA3k_PZ6Fam"
      },
      "source": [
        "labels, _, _ = STC.predict(json_test, explain=False)\n",
        "labels = labels.fillna(0)\n",
        "predictions['Sparse Tensor Classifier'] = labels.target.values.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZC8wOjo-PrS"
      },
      "source": [
        "import sklearn.metrics as mtr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km7to-vNyHyr"
      },
      "source": [
        "E = []\n",
        "for estimator, y_pred in predictions.items():\n",
        "    report = mtr.classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "    E.append({\n",
        "        'Model': estimator, 'Accuracy': report['accuracy'],\n",
        "        'Avg Precision (macro)': report['macro avg']['precision'],\n",
        "        'Avg Recall (macro)': report['macro avg']['recall'],\n",
        "        'Avg F1-score (macro)': report['macro avg']['f1-score'],\n",
        "        'Avg Precision (weighted)': report['weighted avg']['precision'],\n",
        "        'Avg Recall (weighted)': report['weighted avg']['recall'],\n",
        "        'Avg F1-score (weighted)': report['weighted avg']['f1-score']\n",
        "    })\n",
        "E = pd.DataFrame(E).set_index('Model', inplace=False)\n",
        "\n",
        "print(E)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXunKASXbTZ3"
      },
      "source": [
        "## Analysis and tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyiG0ANekCwL"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqERD1icb1XH"
      },
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Woqj6LVQWFVS"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnavuEbmb4JN"
      },
      "source": [
        "def objective(trial):\n",
        "  criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
        "  bootstrap = trial.suggest_categorical('bootstrap',['True','False'])\n",
        "  max_depth = trial.suggest_int('max_depth', 20, 35)\n",
        "  n_estimators =  trial.suggest_int('n_estimators', 50, 300, step=50)\n",
        "    \n",
        "  clf = RandomForestClassifier(bootstrap = bootstrap, criterion = criterion,\n",
        "                                 max_depth = max_depth,\n",
        "                                 n_estimators = n_estimators,n_jobs=-1, class_weight='balanced')\n",
        "  score = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1_weighted\").mean()\n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJo19_F2cLew"
      },
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AOdSLqAcP8J"
      },
      "source": [
        "trial = study.best_trial\n",
        "print('F1 Score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HABRVzjv3e-n"
      },
      "source": [
        "optimised_rf = RandomForestClassifier(bootstrap = study.best_params['bootstrap'], criterion = study.best_params['criterion'],\n",
        "                                    max_depth = study.best_params['max_depth'], n_estimators = study.best_params['n_estimators'], n_jobs=-1, class_weight='balanced')\n",
        "\n",
        "\n",
        "optimised_rf.fit(X_train ,y_train)\n",
        "\n",
        "y_pred = optimised_rf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('The Accuracy Score is:',accuracy_score(y_test, y_pred))\n",
        "print('The Weighted F1 Score is:',f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Confusion Matrix\n",
        "plot_confusion_matrix(optimised_rf, X_test, y_test, normalize= 'true', cmap= 'magma')  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L4PhoeJWMaP"
      },
      "source": [
        "### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEBv3z2hD5T8"
      },
      "source": [
        "def objective(trial):\n",
        "  alpha = trial.suggest_float('alpha', 0.01, 10, log=True)\n",
        "\n",
        "  clf = MultinomialNB(alpha=alpha)\n",
        "\n",
        "  score = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1_weighted\").mean()\n",
        "  return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo8tsLFAD5Ql"
      },
      "source": [
        "trial = study.best_trial\n",
        "print('F1 - Score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPRrm5BfH8Vl"
      },
      "source": [
        "optimised_mnb = MultinomialNB(alpha = study.best_params['alpha'])\n",
        "\n",
        "optimised_mnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = optimised_mnb.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('The Accuracy Score is:',accuracy_score(y_test, y_pred))  \n",
        "print('The Weighted F1 Score is:',f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(optimised_mnb, X_test, y_test, normalize= 'true', cmap= 'magma')  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPm7hTtDQGl7"
      },
      "source": [
        "plot_confusion_matrix(optimised_mnb, X_test, y_test, normalize= 'true', cmap= 'magma')  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-mLdwQnWTal"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNSNBtP214DG"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejWkOzMAj-lO"
      },
      "source": [
        "# optuna's objective function\n",
        "def objective(trial):\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.5, log=True)\n",
        "  max_depth = trial.suggest_int(\"max_depth\", 2, 10,step=2, log=False)\n",
        "  n_estimators = trial.suggest_int(\"n_estimators\", 100, 300,step=100, log=False)\n",
        "\n",
        "  model = XGBClassifier(objective= 'multi:softmax',\n",
        "                        learning_rate = learning_rate,\n",
        "                        n_estimators = n_estimators,\n",
        "                        max_depth = max_depth,\n",
        "                        seed=42)\n",
        "\n",
        "  # Handle pruning based on the intermediate value.\n",
        "  if trial.should_prune():\n",
        "    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1_weighted\").mean()\n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOS5gBTmTe60"
      },
      "source": [
        "# study to maximize the accuracy metric\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vi3b90XT3zp"
      },
      "source": [
        "trial = study.best_trial\n",
        "print('F1 Score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEy13T9d8he7"
      },
      "source": [
        "optimised_xgb = XGBClassifier(objective= 'multi:softmax',\n",
        "                        learning_rate = study.best_params['learning_rate'],\n",
        "                        n_estimators = study.best_params['n_estimators'],\n",
        "                        max_depth = study.best_params['max_depth'],\n",
        "                        seed=42)\n",
        "\n",
        "optimised_xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = optimised_xgb.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('The Accuracy Score is:',accuracy_score(y_test, y_pred))\n",
        "print('The Weighted F1 Score is:',f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Confusion Matrix\n",
        "plot_confusion_matrix(optimised_xgb, X_test, y_test, normalize= 'true', cmap= 'magma')  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}